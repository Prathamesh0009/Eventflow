# Phase 2.3 – Data & Event Model Design

## 1. Purpose

This document defines **how data is structured and stored** in EventFlow, with a strong focus on **event design**, **immutability**, and **future analytics readiness**.

The goal is to design data models that:

* Are simple for MVP
* Reflect real-world event-driven systems
* Can evolve into analytics, BI, or ML pipelines later

---

## 2. Core Data Philosophy

EventFlow follows an **event-first data philosophy**:

* Events are **immutable**
* Events are the **source of truth**
* Derived data can be rebuilt from events
* State is secondary, events are primary

This aligns with:

* Event Sourcing concepts
* Auditability
* Analytics friendliness

---

## 3. Event Model (Core Concept)

### 3.1 What Is an Event?

An event represents:

> “Something that happened in the system at a specific point in time.”

Examples:

* `user_registered`
* `order_created`
* `payment_failed`
* `service_called`

---

### 3.2 Event Structure (Logical Model)

Each event consists of three layers:

1. **Metadata** – system-level information
2. **Payload** – business data
3. **Context** – optional tracing & correlation data

---

### 3.3 Event Schema (Logical)

```json
{
  "event_id": "uuid",
  "event_type": "string",
  "event_version": 1,
  "occurred_at": "timestamp",
  "source": "service-name",
  "stream_name": "string",      // Logical stream/topic name
  "payload": { },               // Business data (flexible JSON)
  "context": {
    "trace_id": "string",
    "correlation_id": "string",
    "api_key_id": "uuid"        // Identifies producer via API key
  }
}
```

**Note:** In the database, this structure is stored across:
- `events.id` = event_id
- `events.stream_id` = References event_streams table
- `events.payload` = Business payload (JSONB)
- `events.metadata` = All system metadata including event_type, version, timestamps, context (JSONB)

---

## 4. Database Design (PostgreSQL)

> **Note:** This document provides the logical event model. For the complete, production-ready database schema with all tables, indexes, and constraints, see **Phase 3.3 – Database Schema Design**.

### 4.1 Core Tables Overview

The production schema includes:

| Table                | Purpose                          |
| -------------------- | --------------------------------- |
| organizations        | Multi-tenant isolation            |
| users                | Dashboard users                   |
| api_keys             | Producer authentication           |
| event_streams        | Logical grouping of events        |
| events               | Immutable event store             |
| consumer_groups      | Logical consumers                |
| consumer_offsets     | Consumption progress tracking     |
| dead_letter_events   | Failed event storage              |

**Full schema details:** See `3.3_database_schema.md` for complete table definitions, indexes, and constraints.

---

## 5. Event-to-Database Mapping

### 5.1 Event Logical Model → Database Schema

The logical event structure maps to the database as follows:

**Logical Event Structure:**
```json
{
  "event_id": "uuid",
  "event_type": "string",      // Stored in metadata.event_type
  "event_version": 1,          // Stored in metadata.event_version
  "occurred_at": "timestamp",  // Stored in metadata.occurred_at
  "source": "service-name",     // Stored in metadata.source
  "producer_id": "string",     // Derived from api_key → org_id
  "payload": { },              // Stored in events.payload (JSONB)
  "context": {                 // Stored in events.metadata.context (JSONB)
    "trace_id": "string",
    "correlation_id": "string"
  }
}
```

**Database Storage:**
- `events.id` = `event_id`
- `events.stream_id` = Maps to `event_streams` (logical grouping)
- `events.payload` = Business payload (JSONB)
- `events.metadata` = Complete system metadata (JSONB) containing:
  - `event_type`
  - `event_version`
  - `occurred_at`
  - `source`
  - `api_key_id` (for producer tracking)
  - `context` (trace_id, correlation_id, etc.)
- `events.created_at` = Ingestion timestamp

### 5.2 Event Streams

Events are organized into **streams** (similar to Kafka topics):
- Each stream belongs to an organization
- Streams can have schema definitions for validation
- Events are linked to streams via `stream_id`

### 5.3 Producer Identification

Producers are identified via:
- `api_keys` table stores API keys per organization
- API key used in request → identifies `org_id`
- Producer information stored in event `metadata.api_key_id`

---

## 6. Why This Model Works

* Simple relational core
* JSON payload allows flexibility
* Strong audit trail
* Easy analytics extraction later

---

## 7. Analytics & Data Science Open End

This model enables:

* ETL to data warehouse
* Event aggregation
* Funnel analysis
* Time-series analytics
* ML feature generation

Without changing core architecture.

---

## 8. Trade-offs (Explicit)

Accepted trade-offs:

* No strict schema enforcement on payload (MVP)
* Potential payload inconsistency

Mitigation (future):

* Schema registry
* Versioned payload validation