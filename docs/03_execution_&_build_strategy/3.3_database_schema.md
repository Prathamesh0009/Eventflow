# Phase 3.3 – Database Schema Design

> **Goal of this phase**
>
> Define a **production-grade relational data model** for EventFlow that supports:
>
> * High write throughput (event ingestion)
> * Reliable consumption (offset tracking)
> * Auditability & replay
> * Future analytics extensions
>
> This schema is designed so that **backend coding can start without revisiting data decisions**.

---

## 1. Database Choice & Rationale

### Primary Database: **PostgreSQL**

**Why PostgreSQL (Germany market aligned):**

* Most widely used relational DB in German startups & enterprises
* Strong ACID guarantees (important for events & offsets)
* Excellent JSONB support (future analytics & flexible payloads)
* Easy migration to managed cloud services (AWS RDS / Aurora)

---

## 2. Core Design Principles

* **Write-optimized for events**
* **Read-optimized for consumers**
* **Immutable event data** (events are never updated)
* **Offsets tracked independently**
* **Soft deletes for control entities**

---

## 3. Entity Overview (Conceptual Model)

```
Organization
  ├── Users
  ├── API Keys
  ├── Event Streams
  │     ├── Events
  │     ├── Consumer Groups
  │           └── Offsets
  └── Dead Letter Events
```

---

## 4. Table Definitions (Detailed)

### 4.1 organizations

Stores tenant-level isolation.

| Column     | Type      | Description       |
| ---------- | --------- | ----------------- |
| id         | UUID (PK) | Organization ID   |
| name       | VARCHAR   | Organization name |
| created_at | TIMESTAMP | Creation time     |
| is_active  | BOOLEAN   | Soft delete flag  |

Indexes:

* `PRIMARY KEY (id)`

---

### 4.2 users

Dashboard users.

| Column        | Type             | Description     |
| ------------- | ---------------- | --------------- |
| id            | UUID (PK)        | User ID         |
| org_id        | UUID (FK)        | Organization    |
| email         | VARCHAR (UNIQUE) | Login email     |
| password_hash | TEXT             | Hashed password |
| role          | VARCHAR          | admin / viewer  |
| created_at    | TIMESTAMP        | Creation time   |
| is_active     | BOOLEAN          | Soft delete     |

Indexes:

* `UNIQUE(email)`
* `INDEX(org_id)`

---

### 4.3 api_keys

Used by producers to send events.

| Column     | Type      | Description         |
| ---------- | --------- | ------------------- |
| id         | UUID (PK) | API key ID          |
| org_id     | UUID (FK) | Organization        |
| key_hash   | TEXT      | Hashed API key      |
| label      | VARCHAR   | Purpose description |
| created_at | TIMESTAMP | Creation time       |
| revoked_at | TIMESTAMP | Revocation time     |

Indexes:

* `INDEX(org_id)`

---

### 4.4 event_streams

Logical grouping of events (similar to topics).

| Column     | Type      | Description             |
| ---------- | --------- | ----------------------- |
| id         | UUID (PK) | Stream ID               |
| org_id     | UUID (FK) | Organization            |
| name       | VARCHAR   | Stream name             |
| schema     | JSONB     | Expected payload schema |
| created_at | TIMESTAMP | Creation time           |
| is_active  | BOOLEAN   | Soft delete             |

Indexes:

* `UNIQUE(org_id, name)`

---

### 4.5 events

Core event store (append-only).

| Column     | Type      | Description     |
| ---------- | --------- | --------------- |
| id         | UUID (PK) | Event ID        |
| stream_id  | UUID (FK) | Event stream    |
| payload    | JSONB     | Event data      |
| metadata   | JSONB     | System metadata |
| created_at | TIMESTAMP | Ingestion time  |

Indexes:

* `INDEX(stream_id, created_at)`
* `GIN(payload)` (future analytics)

Partitioning Strategy:

* Range partition by `created_at` (daily or monthly)

---

### 4.6 consumer_groups

Represents logical consumers.

| Column     | Type      | Description       |
| ---------- | --------- | ----------------- |
| id         | UUID (PK) | Consumer group ID |
| stream_id  | UUID (FK) | Event stream      |
| name       | VARCHAR   | Consumer name     |
| created_at | TIMESTAMP | Creation time     |

Indexes:

* `UNIQUE(stream_id, name)`

---

### 4.7 consumer_offsets

Tracks consumption progress.

| Column            | Type      | Description          |
| ----------------- | --------- | -------------------- |
| id                | UUID (PK) | Offset ID            |
| consumer_group_id | UUID (FK) | Consumer group       |
| last_event_id     | UUID      | Last processed event |
| updated_at        | TIMESTAMP | Last update          |

Indexes:

* `UNIQUE(consumer_group_id)`

---

### 4.8 dead_letter_events

Stores failed events.

| Column    | Type      | Description    |
| --------- | --------- | -------------- |
| id        | UUID (PK) | DLQ event ID   |
| event_id  | UUID      | Original event |
| reason    | TEXT      | Failure reason |
| payload   | JSONB     | Event payload  |
| failed_at | TIMESTAMP | Failure time   |

Indexes:

* `INDEX(event_id)`

---

## 5. Data Integrity & Constraints

* Foreign keys enforced for all relationships
* Cascading deletes avoided (soft delete preferred)
* Events are **never updated or deleted**

---

## 6. Performance Considerations

* Batch inserts for events
* Partition pruning for queries
* Index only on read paths

---

## 7. Data Migration Strategy

### Migration Tool: Prisma Migrate

EventFlow uses **Prisma Migrate** for schema versioning and evolution.

### Migration Principles

* **Schema-first** - Schema defined in `schema.prisma`
* **Immutable migrations** - Once applied, migrations are never modified
* **Forward-only** - Migrations only move forward (no rollback scripts)
* **Idempotent** - Safe to re-run migrations
* **Backward compatible** - New migrations don't break existing data

### Migration Workflow

1. **Update Schema:**
   ```prisma
   // schema.prisma
   model EventStream {
     id        String   @id @default(uuid())
     orgId     String   @map("org_id")
     name      String
     schema    Json?
     createdAt DateTime @default(now()) @map("created_at")
     isActive  Boolean  @default(true) @map("is_active")
     
     @@unique([orgId, name])
     @@map("event_streams")
   }
   ```

2. **Generate Migration:**
   ```bash
   npx prisma migrate dev --name add_event_streams
   ```

3. **Review:** Check generated migration SQL in `prisma/migrations/`

4. **Test:** Migrations run automatically in development

5. **Deploy:** Migrations run automatically on deployment (CI/CD)

### Schema Evolution Rules

* **Additive changes only** (MVP):
  * Adding new fields (with defaults)
  * Adding new models
  * Adding indexes
* **Breaking changes** require:
  * New migration with data transformation
  * Deprecation period for old schema
  * Documentation update

### Example Prisma Schema

```prisma
// schema.prisma
generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model Organization {
  id        String   @id @default(uuid())
  name      String
  createdAt DateTime @default(now()) @map("created_at")
  isActive  Boolean  @default(true) @map("is_active")
  
  users       User[]
  apiKeys     ApiKey[]
  eventStreams EventStream[]
  
  @@map("organizations")
}

model EventStream {
  id        String   @id @default(uuid())
  orgId     String   @map("org_id")
  name      String
  schema    Json?
  createdAt DateTime @default(now()) @map("created_at")
  isActive  Boolean  @default(true) @map("is_active")
  
  organization Organization @relation(fields: [orgId], references: [id])
  events        Event[]
  consumerGroups ConsumerGroup[]
  
  @@unique([orgId, name])
  @@map("event_streams")
}
```

### Migration Execution

* **Local Development:** `npx prisma migrate dev`
* **Staging/Production:** `npx prisma migrate deploy` (via CI/CD)
* **Rollback:** Manual database restore (migrations are forward-only)
* **Generate Client:** `npx prisma generate` (after schema changes)

---

## 8. Analytics & Future Expansion (Open-End)

This schema supports:

* Event aggregation queries
* Time-series analysis
* Export to data lake
* Partitioning by date for performance
* GIN indexes on JSONB for flexible querying