# Phase 3.9 – Monitoring & Alerting Design

> **Goal of this phase**
>
> Define **comprehensive monitoring, logging, and alerting strategy** for EventFlow to ensure production observability and rapid incident response.

---

## 1. Observability Philosophy

### 1.1 Three Pillars of Observability

* **Metrics** - Numerical measurements over time
* **Logs** - Discrete events with context
* **Traces** - Request flow across services

### 1.2 Observability Goals

* **Detect issues** before users notice
* **Debug quickly** with rich context
* **Understand system behavior** in production
* **Make data-driven decisions**

---

## 2. Metrics Strategy

### 2.1 Key Metrics Categories

#### Business Metrics
* Events ingested per second
* Events processed per second
* Consumer lag (events behind)
* Active streams count
* Active consumer groups

#### Technical Metrics
* API request rate
* API latency (p50, p95, p99)
* Error rate (4xx, 5xx)
* Database query latency
* Database connection pool usage
* Redis memory usage
* Container CPU/Memory

#### Infrastructure Metrics
* ECS task count
* RDS CPU/Memory
* Network throughput
* Disk I/O

---

### 2.2 Metrics Collection

**Tool:** AWS CloudWatch + OpenTelemetry

**Implementation:**
```typescript
// Backend metrics
import { Counter, Histogram } from 'prom-client';

const eventsIngested = new Counter({
  name: 'events_ingested_total',
  help: 'Total events ingested',
  labelNames: ['stream_id', 'event_type'],
});

const apiLatency = new Histogram({
  name: 'api_request_duration_seconds',
  help: 'API request latency',
  labelNames: ['method', 'route', 'status'],
});
```

**Export:**
* Prometheus format endpoint: `/metrics`
* CloudWatch integration
* Custom dashboards

---

### 2.3 Metrics Dashboard

**Tool:** AWS CloudWatch Dashboards

**Dashboard Panels:**
1. **Event Ingestion**
   * Events/sec (line chart)
   * Events by stream (bar chart)
   * Ingestion latency (histogram)

2. **API Performance**
   * Request rate
   * Latency (p50, p95, p99)
   * Error rate

3. **Consumer Health**
   * Consumer lag per group
   * Offset commit rate
   * Failed processing count

4. **Infrastructure**
   * CPU/Memory usage
   * Database connections
   * Redis memory

---

## 3. Logging Strategy

### 3.1 Log Levels

* **ERROR** - System errors, exceptions
* **WARN** - Recoverable issues, deprecations
* **INFO** - Important business events
* **DEBUG** - Detailed debugging info (dev only)

### 3.2 Structured Logging

**Format:** JSON

**Example:**
```json
{
  "timestamp": "2026-01-24T10:00:00.000Z",
  "level": "INFO",
  "service": "eventflow-backend",
  "module": "EventService",
  "message": "Event ingested successfully",
  "event_id": "uuid",
  "stream_id": "uuid",
  "event_type": "user_registered",
  "request_id": "uuid",
  "duration_ms": 45,
  "metadata": {
    "org_id": "uuid",
    "api_key_id": "uuid"
  }
}
```

---

### 3.3 Log Aggregation

**Tool:** AWS CloudWatch Logs

**Log Groups:**
* `/eventflow/backend/application`
* `/eventflow/backend/access`
* `/eventflow/backend/errors`
* `/eventflow/frontend/application`

**Retention:**
* Production: 30 days
* Staging: 14 days
* Development: 7 days

---

### 3.4 Log Context

**Request Context:**
* `request_id` - Unique per request
* `trace_id` - Distributed tracing ID
* `user_id` - Authenticated user
* `org_id` - Organization context

**Event Context:**
* `event_id` - Event identifier
* `stream_id` - Stream identifier
* `consumer_group_id` - Consumer context

---

## 4. Distributed Tracing

### 4.1 Tracing Strategy

**Tool:** OpenTelemetry + AWS X-Ray

**Traced Operations:**
* HTTP requests (incoming)
* HTTP requests (outgoing)
* Database queries
* Redis operations
* Event processing

**Trace Structure:**
```
Request
  ├── Authentication
  ├── Validation
  ├── Database Write
  │   └── Event Insert
  └── Response
```

---

### 4.2 Trace Sampling

* **Production:** 10% sampling (cost optimization)
* **Staging:** 100% sampling
* **Development:** 100% sampling
* **Errors:** Always sampled

---

## 5. Alerting Strategy

### 5.1 Alert Severity Levels

* **Critical** - System down, data loss
* **High** - Degraded performance, high error rate
* **Medium** - Warning conditions
* **Low** - Informational

---

### 5.2 Critical Alerts

#### System Health
* **Service Down**
  * Condition: Health check fails for 2 minutes
  * Action: Page on-call engineer
  * Channel: PagerDuty / Slack

* **Database Unavailable**
  * Condition: DB connection failures > 5 in 1 minute
  * Action: Page on-call engineer
  * Channel: PagerDuty

#### Data Integrity
* **High Error Rate**
  * Condition: 5xx errors > 5% for 5 minutes
  * Action: Alert team
  * Channel: Slack

* **Event Ingestion Failure**
  * Condition: Ingestion success rate < 95% for 5 minutes
  * Action: Alert team
  * Channel: Slack

* **Consumer Lag**
  * Condition: Lag > 10,000 events for 10 minutes
  * Action: Alert team
  * Channel: Slack

---

### 5.3 High Priority Alerts

#### Performance
* **High Latency**
  * Condition: p95 latency > 1 second for 10 minutes
  * Action: Alert team
  * Channel: Slack

* **Database Slow Queries**
  * Condition: Query time > 5 seconds
  * Action: Log and alert
  * Channel: Slack

#### Capacity
* **High Memory Usage**
  * Condition: Memory > 85% for 10 minutes
  * Action: Alert team
  * Channel: Slack

* **Database Connection Pool Exhausted**
  * Condition: Pool usage > 90%
  * Action: Alert team
  * Channel: Slack

---

### 5.4 Medium Priority Alerts

* **Rate Limit Approaching**
  * Condition: 80% of rate limit used
  * Action: Inform team
  * Channel: Email

* **Dead Letter Queue Growth**
  * Condition: DLQ size > 100 events
  * Action: Inform team
  * Channel: Email

---

### 5.5 Alert Configuration

**Tool:** AWS CloudWatch Alarms

**Example:**
```yaml
HighErrorRate:
  Metric: ErrorRate
  Threshold: 5%
  Period: 5 minutes
  EvaluationPeriods: 1
  ComparisonOperator: GreaterThanThreshold
  Actions:
    - SNS Topic: alerts-critical
```

---

## 6. Health Checks

### 6.1 Health Endpoint

**Endpoint:** `GET /api/v1/health`

**Response:**
```json
{
  "status": "UP",
  "checks": {
    "database": "UP",
    "redis": "UP",
    "disk": "UP"
  },
  "timestamp": "2026-01-24T10:00:00Z"
}
```

**Checks:**
* Database connectivity
* Redis connectivity
* Disk space
* Memory usage

---

### 6.2 Readiness Probe

**Endpoint:** `GET /api/v1/health/ready`

**Checks:**
* Database ready
* Redis ready
* Application initialized

**Used by:**
* Load balancer
* Kubernetes/ECS
* Deployment tools

---

### 6.3 Liveness Probe

**Endpoint:** `GET /api/v1/health/live`

**Checks:**
* Application running
* No deadlocks

**Used by:**
* Container orchestrator
* Auto-restart on failure

---

## 7. Error Tracking

### 7.1 Error Aggregation

**Tool:** AWS CloudWatch Logs Insights + Custom Dashboard

**Error Types Tracked:**
* Application exceptions
* Database errors
* Validation errors
* Authentication failures

**Error Dashboard:**
* Error rate over time
* Top errors by count
* Error rate by endpoint
* Error trends

---

### 7.2 Exception Handling

**Structured Error Logging:**
```json
{
  "timestamp": "2026-01-24T10:00:00Z",
  "level": "ERROR",
  "error": {
    "type": "ValidationError",
    "message": "Invalid event payload",
    "stack": "...",
    "context": {
      "event_id": "uuid",
      "stream_id": "uuid"
    }
  },
  "request_id": "uuid"
}
```

---

## 8. Performance Monitoring

### 8.1 APM (Application Performance Monitoring)

**Tool:** AWS X-Ray or New Relic (future)

**Monitored Operations:**
* API endpoint performance
* Database query performance
* External API calls
* Event processing time

**Key Metrics:**
* Response time percentiles
* Throughput
* Error rate
* Apdex score

---

### 8.2 Database Performance

**Monitored:**
* Slow queries (> 1 second)
* Query execution plans
* Index usage
* Connection pool metrics

**Tools:**
* PostgreSQL `pg_stat_statements`
* CloudWatch RDS metrics
* Custom query logging

---

## 9. Custom Dashboards

### 9.1 Operations Dashboard

**Panels:**
1. System health overview
2. Event ingestion rate
3. API performance
4. Error rate
5. Consumer lag
6. Infrastructure metrics

**Refresh:** 30 seconds

---

### 9.2 Business Dashboard

**Panels:**
1. Events ingested (total, by stream)
2. Active streams
3. Active consumer groups
4. Events processed
5. Consumer lag trends

**Refresh:** 5 minutes

---

## 10. Log Analysis

### 10.1 CloudWatch Logs Insights

**Common Queries:**

```sql
-- Error rate by endpoint
fields @timestamp, @message
| filter level = "ERROR"
| stats count() by route

-- Slow requests
fields @timestamp, duration_ms
| filter duration_ms > 1000
| sort duration_ms desc
| limit 100

-- Events by type
fields @timestamp, event_type
| stats count() by event_type
```

---

## 11. Incident Response

### 11.1 On-Call Rotation

* **Primary:** On-call engineer
* **Secondary:** Backup engineer
* **Rotation:** Weekly

### 11.2 Incident Process

1. **Detection** - Alert triggered
2. **Acknowledgment** - On-call acknowledges
3. **Investigation** - Review logs, metrics, traces
4. **Mitigation** - Fix or rollback
5. **Resolution** - Issue resolved
6. **Post-Mortem** - Document learnings

---

## 12. Monitoring Tools Summary

| Tool              | Purpose                    |
| ----------------- | -------------------------- |
| AWS CloudWatch     | Metrics, logs, alarms      |
| AWS X-Ray          | Distributed tracing         |
| OpenTelemetry      | Instrumentation            |
| Prometheus         | Metrics (optional)          |
| Grafana            | Dashboards (optional)       |
| PagerDuty          | Alert routing              |
| Slack              | Team notifications         |

---

## 13. Cost Optimization

### 13.1 Log Retention

* Production: 30 days
* Staging: 14 days
* Development: 7 days

### 13.2 Metric Retention

* High-resolution: 15 days
* Standard: 63 days
* Aggregated: 15 months

### 13.3 Sampling

* Traces: 10% in production
* Logs: Full (already filtered)

---

## 14. Future Enhancements

* **Real-time dashboards** - WebSocket updates
* **Anomaly detection** - ML-based alerting
* **SLO/SLI tracking** - Service level objectives
* **User experience monitoring** - Frontend metrics
* **Synthetic monitoring** - Automated health checks

---

## 15. Summary

EventFlow monitoring & alerting provides:

* ✅ Comprehensive metrics (business + technical)
* ✅ Structured logging with context
* ✅ Distributed tracing
* ✅ Multi-level alerting
* ✅ Health checks
* ✅ Error tracking
* ✅ Performance monitoring
* ✅ Incident response process

This ensures **full observability** and **rapid incident response** in production.
